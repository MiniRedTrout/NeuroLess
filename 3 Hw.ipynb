{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T18:52:07.981711Z",
     "iopub.status.busy": "2025-10-25T18:52:07.981150Z",
     "iopub.status.idle": "2025-10-25T18:52:07.985799Z",
     "shell.execute_reply": "2025-10-25T18:52:07.985014Z",
     "shell.execute_reply.started": "2025-10-25T18:52:07.981684Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_path = '/kaggle/input/cards-image-datasetclassification/train'\n",
    "test_path = '/kaggle/input/cards-image-datasetclassification/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T18:52:07.986908Z",
     "iopub.status.busy": "2025-10-25T18:52:07.986609Z",
     "iopub.status.idle": "2025-10-25T18:52:26.918044Z",
     "shell.execute_reply": "2025-10-25T18:52:26.916911Z",
     "shell.execute_reply.started": "2025-10-25T18:52:07.986879Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torchvision import transforms, datasets\n",
    "from torchmetrics import Accuracy\n",
    "from torch.utils.data import DataLoader,Subset\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T18:52:26.920991Z",
     "iopub.status.busy": "2025-10-25T18:52:26.920511Z",
     "iopub.status.idle": "2025-10-25T18:52:26.930560Z",
     "shell.execute_reply": "2025-10-25T18:52:26.929227Z",
     "shell.execute_reply.started": "2025-10-25T18:52:26.920965Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T18:52:26.931939Z",
     "iopub.status.busy": "2025-10-25T18:52:26.931626Z",
     "iopub.status.idle": "2025-10-25T18:52:26.956748Z",
     "shell.execute_reply": "2025-10-25T18:52:26.955512Z",
     "shell.execute_reply.started": "2025-10-25T18:52:26.931916Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.RandomRotation(degrees=10),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )])\n",
    "basic_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T18:52:26.958825Z",
     "iopub.status.busy": "2025-10-25T18:52:26.958311Z",
     "iopub.status.idle": "2025-10-25T18:52:31.449157Z",
     "shell.execute_reply": "2025-10-25T18:52:31.448226Z",
     "shell.execute_reply.started": "2025-10-25T18:52:26.958790Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(train_path,transform=train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T18:52:31.450306Z",
     "iopub.status.busy": "2025-10-25T18:52:31.450051Z",
     "iopub.status.idle": "2025-10-25T18:52:31.523828Z",
     "shell.execute_reply": "2025-10-25T18:52:31.522588Z",
     "shell.execute_reply.started": "2025-10-25T18:52:31.450285Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_dataset = datasets.ImageFolder(test_path,transform=basic_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T18:52:31.525181Z",
     "iopub.status.busy": "2025-10-25T18:52:31.524865Z",
     "iopub.status.idle": "2025-10-25T18:52:31.532032Z",
     "shell.execute_reply": "2025-10-25T18:52:31.531133Z",
     "shell.execute_reply.started": "2025-10-25T18:52:31.525153Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_dataset.classes\n",
    "len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T18:52:31.533142Z",
     "iopub.status.busy": "2025-10-25T18:52:31.532889Z",
     "iopub.status.idle": "2025-10-25T18:52:31.553240Z",
     "shell.execute_reply": "2025-10-25T18:52:31.552461Z",
     "shell.execute_reply.started": "2025-10-25T18:52:31.533124Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 7624\n",
       "    Root location: /kaggle/input/cards-image-datasetclassification/train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
       "               RandomHorizontalFlip(p=0.5)\n",
       "               RandomRotation(degrees=[-10.0, 10.0], interpolation=nearest, expand=False, fill=0)\n",
       "               RandomAffine(degrees=[0.0, 0.0], translate=(0.1, 0.1))\n",
       "               ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=None, hue=None)\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "           )"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T18:52:31.555743Z",
     "iopub.status.busy": "2025-10-25T18:52:31.555487Z",
     "iopub.status.idle": "2025-10-25T18:52:31.572593Z",
     "shell.execute_reply": "2025-10-25T18:52:31.571494Z",
     "shell.execute_reply.started": "2025-10-25T18:52:31.555723Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T18:52:31.574418Z",
     "iopub.status.busy": "2025-10-25T18:52:31.574056Z",
     "iopub.status.idle": "2025-10-25T18:52:32.600993Z",
     "shell.execute_reply": "2025-10-25T18:52:32.599950Z",
     "shell.execute_reply.started": "2025-10-25T18:52:31.574360Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def AlexNet(num_classes=53):\n",
    "  def _initialize_weights(m):\n",
    "        if type(m) == torch.nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            torch.nn.init.constant_(m.bias, 0.0)\n",
    "        if type(m) == torch.nn.Conv2d:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "              torch.nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "  net = nn.Sequential(\n",
    "        nn.Conv2d(3, 96, kernel_size=11, stride=4,padding=2),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "\n",
    "        nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "\n",
    "        nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        nn.AdaptiveAvgPool2d((6, 6)),\n",
    "        nn.Flatten(),\n",
    "\n",
    "        nn.Linear(256 * 6 * 6, 4096),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.5),\n",
    "\n",
    "        nn.Linear(4096, 4096),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(4096, num_classes))\n",
    "  net.apply(_initialize_weights)\n",
    "\n",
    "  return net\n",
    "\n",
    "# Создание модели\n",
    "model = AlexNet(num_classes=len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T18:52:32.602664Z",
     "iopub.status.busy": "2025-10-25T18:52:32.602192Z",
     "iopub.status.idle": "2025-10-25T18:52:32.607422Z",
     "shell.execute_reply": "2025-10-25T18:52:32.606490Z",
     "shell.execute_reply.started": "2025-10-25T18:52:32.602632Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T18:52:32.608567Z",
     "iopub.status.busy": "2025-10-25T18:52:32.608292Z",
     "iopub.status.idle": "2025-10-25T18:52:32.636724Z",
     "shell.execute_reply": "2025-10-25T18:52:32.635682Z",
     "shell.execute_reply.started": "2025-10-25T18:52:32.608547Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (7): ReLU(inplace=True)\n",
       "  (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (9): ReLU(inplace=True)\n",
       "  (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace=True)\n",
       "  (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (13): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (14): Flatten(start_dim=1, end_dim=-1)\n",
       "  (15): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "  (16): ReLU(inplace=True)\n",
       "  (17): Dropout(p=0.5, inplace=False)\n",
       "  (18): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (19): ReLU(inplace=True)\n",
       "  (20): Dropout(p=0.5, inplace=False)\n",
       "  (21): Linear(in_features=4096, out_features=53, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.01,momentum=0.9,weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "def simple_accuracy(preds, targets):\n",
    "    return (preds == targets).float().mean()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T18:52:32.637931Z",
     "iopub.status.busy": "2025-10-25T18:52:32.637685Z",
     "iopub.status.idle": "2025-10-25T21:05:19.803305Z",
     "shell.execute_reply": "2025-10-25T21:05:19.802424Z",
     "shell.execute_reply.started": "2025-10-25T18:52:32.637913Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 1/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [09:42<00:00,  4.86s/it, Loss=3.6641, Avg Loss=3.8875]\n",
      "Evaluating: 100%|██████████| 5/5 [00:08<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.8875, Train Acc: 0.0317\n",
      "Test Loss: 3.6018, Test Acc: 0.0943\n",
      "\n",
      "Эпоха 2/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [08:40<00:00,  4.33s/it, Loss=2.9126, Avg Loss=3.2402]\n",
      "Evaluating: 100%|██████████| 5/5 [00:06<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.2402, Train Acc: 0.1229\n",
      "Test Loss: 3.3423, Test Acc: 0.1208\n",
      "\n",
      "Эпоха 3/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [08:40<00:00,  4.34s/it, Loss=2.8439, Avg Loss=2.7252]\n",
      "Evaluating: 100%|██████████| 5/5 [00:06<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.7252, Train Acc: 0.2269\n",
      "Test Loss: 2.0238, Test Acc: 0.3094\n",
      "\n",
      "Эпоха 4/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [08:42<00:00,  4.35s/it, Loss=3.2056, Avg Loss=2.3970]\n",
      "Evaluating: 100%|██████████| 5/5 [00:06<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.3970, Train Acc: 0.2888\n",
      "Test Loss: 1.8874, Test Acc: 0.3736\n",
      "\n",
      "Эпоха 5/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [08:50<00:00,  4.42s/it, Loss=1.8425, Avg Loss=2.2277]\n",
      "Evaluating: 100%|██████████| 5/5 [00:07<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.2277, Train Acc: 0.3249\n",
      "Test Loss: 1.8258, Test Acc: 0.4189\n",
      "\n",
      "Эпоха 6/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [08:43<00:00,  4.36s/it, Loss=2.5154, Avg Loss=1.9959]\n",
      "Evaluating: 100%|██████████| 5/5 [00:06<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.9959, Train Acc: 0.3972\n",
      "Test Loss: 1.4978, Test Acc: 0.5585\n",
      "\n",
      "Эпоха 7/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [08:49<00:00,  4.42s/it, Loss=1.1115, Avg Loss=1.8024]\n",
      "Evaluating: 100%|██████████| 5/5 [00:06<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8024, Train Acc: 0.4760\n",
      "Test Loss: 1.2068, Test Acc: 0.6453\n",
      "\n",
      "Эпоха 8/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [08:38<00:00,  4.32s/it, Loss=1.2416, Avg Loss=1.6275]\n",
      "Evaluating: 100%|██████████| 5/5 [00:06<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6275, Train Acc: 0.5412\n",
      "Test Loss: 1.1517, Test Acc: 0.7245\n",
      "\n",
      "Эпоха 9/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [08:36<00:00,  4.31s/it, Loss=1.8699, Avg Loss=1.5261]\n",
      "Evaluating: 100%|██████████| 5/5 [00:06<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5261, Train Acc: 0.5787\n",
      "Test Loss: 1.1565, Test Acc: 0.6377\n",
      "\n",
      "Эпоха 10/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [08:38<00:00,  4.32s/it, Loss=0.2534, Avg Loss=1.4607]\n",
      "Evaluating: 100%|██████████| 5/5 [00:06<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4607, Train Acc: 0.5901\n",
      "Test Loss: 0.8739, Test Acc: 0.7283\n",
      "\n",
      "Эпоха 11/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [08:37<00:00,  4.31s/it, Loss=1.3143, Avg Loss=1.2869]\n",
      "Evaluating: 100%|██████████| 5/5 [00:06<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2869, Train Acc: 0.6402\n",
      "Test Loss: 0.7213, Test Acc: 0.7774\n",
      "\n",
      "Эпоха 12/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [08:38<00:00,  4.32s/it, Loss=1.1129, Avg Loss=1.2292]\n",
      "Evaluating: 100%|██████████| 5/5 [00:06<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2292, Train Acc: 0.6533\n",
      "Test Loss: 0.7395, Test Acc: 0.7849\n",
      "\n",
      "Эпоха 13/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [08:35<00:00,  4.30s/it, Loss=1.0427, Avg Loss=1.1974]\n",
      "Evaluating: 100%|██████████| 5/5 [00:06<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1974, Train Acc: 0.6672\n",
      "Test Loss: 0.7108, Test Acc: 0.8000\n",
      "\n",
      "Эпоха 14/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [08:34<00:00,  4.29s/it, Loss=0.5872, Avg Loss=1.1379]\n",
      "Evaluating: 100%|██████████| 5/5 [00:06<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1379, Train Acc: 0.6817\n",
      "Test Loss: 0.8145, Test Acc: 0.8151\n",
      "\n",
      "Эпоха 15/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 120/120 [08:35<00:00,  4.30s/it, Loss=1.6757, Avg Loss=1.1179]\n",
      "Evaluating: 100%|██████████| 5/5 [00:06<00:00,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1179, Train Acc: 0.6857\n",
      "Test Loss: 0.7735, Test Acc: 0.7925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "#Тренирует\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc='Training')\n",
    "    for batch_idx, (data, target) in enumerate(progress_bar):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        all_preds.append(predicted)\n",
    "        all_targets.append(target)\n",
    "        progress_bar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'Avg Loss': f'{running_loss/(batch_idx+1):.4f}'\n",
    "        })\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = simple_accuracy(torch.cat(all_preds), torch.cat(all_targets))\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "#Тестит\n",
    "def evaluate(model, dataloader, criterion, device,matrix=0):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(dataloader, desc='Evaluating'):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            all_preds.append(predicted.cpu())\n",
    "            all_targets.append(target.cpu())\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = simple_accuracy(torch.cat(all_preds), torch.cat(all_targets))\n",
    "    if matrix != 0:\n",
    "        all_preds2 = np.concatenate(all_preds)\n",
    "        all_targets2 = np.concatenate(all_targets)\n",
    "        print()\n",
    "        print(classification_report(all_targets2, all_preds2, target_names=class_names))\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "epochs = 15\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nЭпоха {epoch+1}/{epochs}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc.cpu())\n",
    "\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_acc.cpu())\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T21:05:19.804653Z",
     "iopub.status.busy": "2025-10-25T21:05:19.804349Z",
     "iopub.status.idle": "2025-10-25T21:05:26.252604Z",
     "shell.execute_reply": "2025-10-25T21:05:26.251738Z",
     "shell.execute_reply.started": "2025-10-25T21:05:19.804635Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:06<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     ace of clubs       0.42      1.00      0.59         5\n",
      "  ace of diamonds       1.00      1.00      1.00         5\n",
      "    ace of hearts       0.56      1.00      0.71         5\n",
      "    ace of spades       0.83      1.00      0.91         5\n",
      "   eight of clubs       1.00      1.00      1.00         5\n",
      "eight of diamonds       0.83      1.00      0.91         5\n",
      "  eight of hearts       1.00      1.00      1.00         5\n",
      "  eight of spades       1.00      0.80      0.89         5\n",
      "    five of clubs       0.75      0.60      0.67         5\n",
      " five of diamonds       1.00      0.80      0.89         5\n",
      "   five of hearts       1.00      1.00      1.00         5\n",
      "   five of spades       1.00      1.00      1.00         5\n",
      "    four of clubs       0.80      0.80      0.80         5\n",
      " four of diamonds       0.83      1.00      0.91         5\n",
      "   four of hearts       0.71      1.00      0.83         5\n",
      "   four of spades       0.75      0.60      0.67         5\n",
      "    jack of clubs       1.00      0.60      0.75         5\n",
      " jack of diamonds       1.00      0.40      0.57         5\n",
      "   jack of hearts       1.00      0.60      0.75         5\n",
      "   jack of spades       1.00      0.60      0.75         5\n",
      "            joker       1.00      0.20      0.33         5\n",
      "    king of clubs       0.83      1.00      0.91         5\n",
      " king of diamonds       0.50      0.80      0.62         5\n",
      "   king of hearts       0.80      0.80      0.80         5\n",
      "   king of spades       0.75      0.60      0.67         5\n",
      "    nine of clubs       1.00      0.60      0.75         5\n",
      " nine of diamonds       1.00      0.80      0.89         5\n",
      "   nine of hearts       0.83      1.00      0.91         5\n",
      "   nine of spades       1.00      0.40      0.57         5\n",
      "   queen of clubs       0.50      0.60      0.55         5\n",
      "queen of diamonds       0.50      0.60      0.55         5\n",
      "  queen of hearts       0.67      0.80      0.73         5\n",
      "  queen of spades       0.42      1.00      0.59         5\n",
      "   seven of clubs       1.00      0.80      0.89         5\n",
      "seven of diamonds       1.00      0.80      0.89         5\n",
      "  seven of hearts       0.71      1.00      0.83         5\n",
      "  seven of spades       0.62      1.00      0.77         5\n",
      "     six of clubs       0.50      0.40      0.44         5\n",
      "  six of diamonds       1.00      0.80      0.89         5\n",
      "    six of hearts       0.60      0.60      0.60         5\n",
      "    six of spades       1.00      1.00      1.00         5\n",
      "     ten of clubs       0.83      1.00      0.91         5\n",
      "  ten of diamonds       1.00      0.80      0.89         5\n",
      "    ten of hearts       1.00      0.80      0.89         5\n",
      "    ten of spades       0.80      0.80      0.80         5\n",
      "   three of clubs       1.00      0.60      0.75         5\n",
      "three of diamonds       0.83      1.00      0.91         5\n",
      "  three of hearts       1.00      1.00      1.00         5\n",
      "  three of spades       1.00      0.80      0.89         5\n",
      "     two of clubs       1.00      0.80      0.89         5\n",
      "  two of diamonds       1.00      0.80      0.89         5\n",
      "    two of hearts       0.75      0.60      0.67         5\n",
      "    two of spades       1.00      0.60      0.75         5\n",
      "\n",
      "         accuracy                           0.79       265\n",
      "        macro avg       0.85      0.79      0.79       265\n",
      "     weighted avg       0.85      0.79      0.79       265\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "final_test_loss, final_test_acc = evaluate(model, test_loader, criterion, device, 1)\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2579480,
     "sourceId": 4532039,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
